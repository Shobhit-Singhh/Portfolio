def project_details():
    projects = {
        "Industry Projects": {
            "Development and Automation of Data-Driven Manufacturing Monitoring System": {
                "Role": "Senior Data Scientist @ Primary HealthTech",
                "Objective": "To design and implement an automated data extraction, analysis, and real-time monitoring system for manufacturing processes, enhancing efficiency and minimizing manual intervention.",
                "Key Responsibilities and Achievements": [
                    "Implemented Python scripts leveraging Pandas for data extraction from testing files across 4 wavelengths (528, 620, 367, 405).",
                    "Developed algorithms to calculate statistical measures and store data in Pandas DataFrames for Levels L1, L3, L5, and L6.",
                    "Enabled comparison with reference data (Level L7) to identify deviations and troubleshoot errors efficiently.",
                    "Integrated Plotly for interactive data visualization, aiding in error traceback and defect identification across all operational levels."
                ],
                "Real-Time Manufacturing Monitoring Dashboard": [
                    "Designed and developed a GUI using Tkinter, allowing interactive selection of batch and lot numbers for focused monitoring.",
                    "Implemented wavelength filters (528, 620, 367, 405) for tailored analysis through dynamic graphs and charts.",
                    "Utilized Matplotlib for real-time conversion rates graph, enabling stakeholders to track production efficiency trends.",
                    "Created various bar graphs showcasing manufacturing metrics across different operational levels, facilitating actionable insights for decision-making."
                ],
                "Automation of Device Testing": [
                    "Automated testing processes for Levels L1 and L5, reducing manual intervention and ensuring consistency.",
                    "Standardized procedures for Levels L3 and L6 through Python scripting, minimizing potential errors and enhancing reliability."
                ],
                "Key Technologies and Tools": [
                    "Python (Pandas, Plotly, Tkinter, Matplotlib) for data extraction, analysis, visualization, and automation.",
                    "Figma for UI/UX design, ensuring intuitive dashboard usability.",
                    "Microsoft Excel integration for source file management and data interoperability.",
                    "Shell scripting for system automation tasks, ensuring seamless integration across platforms."
                ],
                "Skills Utilized": [
                    "Software Development (Python, Tkinter)",
                    "Data Extraction and Analysis (Pandas, Plotly)",
                    "Real-Time Dashboard Development (Matplotlib, Tkinter)",
                    "UI/UX Design (Figma)",
                    "Automation Scripting (Python, Shell)",
                    "Project Management and Coordination"
                ]
            },
            "Development and Validation of Data-Driven Analytical Reagent Kit and Device for Clinical Diagnostics": {
                "Role": "Senior Data Scientist @ Primary HealthTech",
                "Objective": "To leverage data science methodologies for developing, optimizing, and validating a reagent kit and associated device for clinical diagnostics, ensuring accurate and reliable performance through data-driven insights.",
                "Key Responsibilities and Achievements": [
                    "Designed and implemented data collection protocols to gather comprehensive reagent kit specifications, including mode of reaction, wavelength requirements, standard concentrations, blank and incubation parameters, detection limits, and measurement protocols.",
                    "Utilized data analytics to define device specifications for primary and secondary wavelengths, temperature profiles, and device linearity and detection limits.",
                    "Created data-driven flowcharts to optimize test flow, timing, and temperature, validated through extensive experimental data analysis.",
                    "Analyzed UV-Vis spectra data for aqueous and serum samples to compare performance across different media."
                ],
                "Data-Driven Device Development": [
                    "Analyzed experimental data to specify the optical core components and versions.",
                    "Conducted statistical analysis on major electrical components, including LED and sensor specifications, to ensure optimal performance.",
                    "Utilized data modeling to define mixer configurations, including version, RPM, and mixing times necessary for optimal test performance."
                ],
                "Device Stability and Reliability Testing": [
                    "Performed sensor and electronics stability tests, including dark current, linearity, and temperature stability, through advanced data analysis techniques.",
                    "Executed continuous blank and water tests, ensuring a coefficient of variation (CV) within specified limits using statistical quality control methods.",
                    "Conducted reinsertion tests with water and dye-filled cuvettes, employing data analytics to confirm device precision and repeatability.",
                    "Implemented data traceability validation using dye and aqueous samples, comparing device performance against UV-Vis spectrophotometer data."
                ],
                "Test Method Validation": [
                    "Established device linearity through regression analysis of multiple samples, verifying the assay range and achieving R² > 0.95.",
                    "Evaluated analytical sensitivity parameters (LOB, LOD, LOQ) using statistical analysis and data modeling techniques.",
                    "Conducted precision studies, utilizing data analytics to assess inter-assay and intra-assay precision with extensive experimental runs.",
                    "Ensured reproducibility across different devices, days, lots, and users by analyzing data from rigorous testing protocols.",
                    "Investigated potential interferences by spiking control samples at different levels, using data analytics to assess impact."
                ],
                "Clinical Performance Evaluation": [
                    "Tested a broad range of clinical samples, applying data analytics to validate the device’s sensitivity, specificity, accuracy, and predictive values.",
                    "Developed method comparison plots (Bland-Altman and Passing Bablok) using statistical software to assess performance against established standards.",
                    "Conducted comprehensive method validation tests, including sensitivity, specificity, accuracy, and predictive values calculations, with demographic data analysis for patient samples."
                ],
                "Key Skills": [
                    "Data Science and Analytics",
                    "Statistical Analysis and Modeling",
                    "Regression and Predictive Modeling",
                    "Data Collection and Management",
                    "Quality Control and Assurance",
                    "Clinical Data Analysis",
                    "Experimental Design and Optimization",
                    "Project Management"
                ]
            },
        },

        "Personal Projects": {
            "Advanced-Data Visualization and Exploration Platform": {
                "Role": "Data Sciene Hackathon Participant",
                "Objective": "Develop an all-in-one data science application for exploratory data analysis, hyper-parameter tuning, and model training, enhancing accessibility to machine learning tools.",
                "Key Features": [
                    "Interactive Data Exploration: Utilize drag-and-drop functionalities for seamless model training and hyper-parameter tuning.",
                    "Comprehensive Data Visualization: Leverage Python libraries such as Matplotlib, Plotly, and custom components for insightful data visualizations.",
                    "Data Cleaning and Preparation: Easily handle data cleaning tasks like removing duplicates, handling missing values, and data type conversion.",
                    "Statistical Insights: Gain deeper insights with correlation matrices, distribution comparisons, and descriptive statistics.",
                    "Machine Learning Model Training: Streamline model building with integrated machine learning algorithms from Scikit-learn and others.",
                    "Dimensionality Reduction: Visualize high-dimensional data using techniques like PCA, t-SNE, and UMAP.",
                    "Model Evaluation and Interpretation: Assess model performance with detailed metrics and visualizations for regression, classification, and clustering tasks."
                ],
                "Technology Stack": [
                    "Backend: Python, Numpy, Pandas, Scikit-learn",
                    "Visualization: Matplotlib, Plotly",
                    "Web Framework: Streamlit"
                ],
                "How It Works": [
                    "Upload Data: Easily upload datasets and explore basic statistics like shape, null values, and duplicates.",
                    "Interactive Visualizations: Generate various plots including scatter plots, histograms, box plots, and heatmaps.",
                    "Data Cleaning: Cleanse data effortlessly with tools for handling duplicates, missing values, and feature engineering.",
                    "Machine Learning: Train and evaluate models with a variety of algorithms such as Linear Regression, Logistic Regression, SVM, Decision Trees, Random Forest, and more.",
                    "Dimensionality Reduction: Visualize and analyze high-dimensional data using PCA, t-SNE, and UMAP.",
                    "Model Deployment: Export trained models and integrate them into production environments."
                ],
                "Who Can Benefit": [
                    "Data Scientists: Rapidly prototype and validate models.",
                    "Business Analysts: Perform exploratory data analysis without coding.",
                    "Educators: Teach fundamental concepts of machine learning in an interactive manner.",
                    "Entrepreneurs: Quickly validate hypotheses and derive insights from data."
                ],
                "Key Skills": [
                    "Data Science and Machine Learning",
                    "Software Development (Python)",
                    "Data Visualization (Matplotlib, Plotly)",
                    "Web Application Development (Streamlit)",
                    "Statistical Analysis and Modeling",
                    "Machine Learning Model Evaluation",
                    "Dimensionality Reduction Techniques",
                    "Data Cleaning and Preprocessing"
                ]
            },

            "Automated Educational Assessment Tool": {
                "Role": "Data Scientist / NLP Engineer",
                "Objective": "Develop an AI-driven tool to revolutionize educational assessment creation by automating the generation of diverse question types (MCQ, MSQ, True/False, Fill in the Blanks, Match the Following). This tool aims to significantly reduce the time and effort required for educators and content creators to develop assessments, thereby enhancing productivity and focusing more on teaching quality.",
                "Key Features": [
                    "Text-to-Text Framework: Utilize T5 for versatile question generation tasks, allowing flexible input-output formats.",
                    "Language Modeling: Implement Ward Net’s advanced models to ensure grammatical correctness and contextual relevance of generated questions.",
                    "Semantic Analysis: Apply Sen2Vec for deep semantic understanding, ensuring coherence and relevance in generated questions.",
                    "Distractor Generation for MCQs: Utilize Wordnet, ConceptNet, and Sense2vec to generate plausible distractors that enhance the complexity and effectiveness of MCQ assessments.",
                    "True or False Question Generation: Implement models like Sentence BERT and GPT-2 for generating accurate True/False questions based on comprehensive linguistic analysis.",
                    "MCQ Generation from Any Content: Leverage T5 transformers and train models using the SQUAD dataset to generate MCQs from varied educational content, ensuring adaptability and relevance.",
                    "Fill in the Blanks Question Generation: Extract keywords using Python Keyword extraction library and visualize using HTML ElementTree in Colab to create interactive fill-in-the-blank questions.",
                    "Match the Following Question Generation: Utilize BERT for Word Sense Disambiguation (WSD) and Python Keyword extraction library for precise keyword matching, enabling creation of engaging match-the-following questions."
                ],
                "Technologies Used": [
                    "T5 (Text-To-Text Transfer Transformer) for versatile text generation tasks.",
                    "Ward Net’s Language Modeling for grammatical correctness and contextual understanding.",
                    "Sen2Vec’s Semantic Analysis for ensuring semantic coherence in generated questions.",
                    "Spacy, NLTK, AllenNLP, HuggingFace Transformers, etc., for natural language processing tasks and model implementations."
                ],
                "Results": "The implementation of our NLP-driven tool has demonstrated a remarkable 70-80% reduction in the time required for manual question framing. This efficiency gain allows educators to allocate more time to instructional planning and personalized teaching strategies, thereby improving overall educational outcomes.",
                "Conclusion": "The Automated Educational Assessment Tool represents a transformative advancement in educational technology, empowering educators and content creators with a powerful AI-driven solution for streamlined assessment creation. By automating tedious tasks, this tool enhances productivity, fosters educational innovation, and ultimately improves the learning experience for students.",
                "Extended Information": "For detailed documentation, including implementation specifics and codebase, please refer to our project repository. We welcome contributions and feedback as we continue to enhance and refine this valuable educational resource."
            }

        }

    }

    return projects
